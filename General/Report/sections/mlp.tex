\section{Neural Network model}
The neural network model is a Multi-Layer Perceptron (MLP) designed to predict the quality of pointclouds based on their extracted features. The architecture consists of an input layer, four hidden layers, and an output layer. The hidden layers have 64, 128, 128, and 64 units, respectively, and use the ReLU activation function to introduce non-linearity. The output layer consists of a single unit that produces the final prediction. The model is implemented using the FLAX NNX framework, which is part of the JAX ecosystem, enabling efficient automatic differentiation and GPU acceleration. Training is performed using the Adam optimizer with a learning rate of 0.001 and a large batch size of 200,000. The network minimizes the mean squared error (MSE) between the predicted values and the ground truth.




\subsection{Performance metrics}
\begin{table}[htbp]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Score} & \textbf{Small model} & \textbf{Big model} \\
\hline
R\textsuperscript{2} & 0.9818 & 0.9910 \\
MAE & 0.0425 & 0.0318 \\
MSE & 0.0137 & 0.0068 \\
RMSE & 0.1170 & 0.0825 \\
Max error & 1.8672 & 1.6806 \\
\hline
\end{tabular}
\vspace{0.5em}  % Adjust as needed
\caption{Comparison of model evaluation metrics between models.}
\label{tab:model_metrics}
\end{table}